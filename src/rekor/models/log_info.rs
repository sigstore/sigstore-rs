/*
 * Rekor
 *
 * Rekor is a cryptographically secure, immutable transparency log for signed software releases.
 *
 * The version of the OpenAPI document: 0.0.1
 *
 * Generated by: https://openapi-generator.tech
 */

use crate::crypto::CosignVerificationKey;
use crate::crypto::merkle::hex_to_hash_output;
use crate::errors::SigstoreError;
use crate::rekor::TreeSize;
use crate::rekor::models::ConsistencyProof;
use crate::rekor::models::checkpoint::Checkpoint;

use serde::{Deserialize, Serialize};

/// Used to deserialize responses of the Rekor API.
#[derive(Serialize, Deserialize)]
pub struct RekorLogInfo {
    /// The current hash value stored at the root of the merkle tree
    #[serde(rename = "rootHash")]
    pub root_hash: String,
    /// The current number of nodes in the merkle tree
    #[serde(rename = "treeSize")]
    pub tree_size: TreeSize,
    /// The current signed tree head
    #[serde(rename = "signedTreeHead")]
    pub signed_tree_head: Checkpoint,
    /// The current treeID
    #[serde(rename = "treeID")]
    pub tree_id: Option<String>,
    /// Optional list of inactive shards that may still be valid for auditing purposes
    #[serde(rename = "inactiveShards", skip_serializing_if = "Option::is_none")]
    pub inactive_shards: Option<Vec<crate::rekor::models::InactiveShardLogInfo>>,
}

/// LogInfo represents the current state of a Rekor transparency log.
///
/// This struct is typically constructed from the log's API response in [`RekorLogInfo`].
///
/// Used to verify log consistency, inclusion proofs, and auditing the log's
/// append-only property.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct LogInfo {
    /// The current hash value, in bytestring, stored at the root of the merkle tree
    pub root_hash: [u8; 32],
    /// The current number of nodes in the merkle tree
    pub tree_size: TreeSize,
    /// The current signed tree head
    pub signed_tree_head: Checkpoint,
    /// The current treeID
    pub tree_id: Option<String>,
    /// Optional list of inactive shards that may still be valid for auditing purposes
    pub inactive_shards: Option<Vec<crate::rekor::models::InactiveShardLogInfo>>,
}

impl TryFrom<RekorLogInfo> for LogInfo {
    type Error = crate::errors::SigstoreError;
    fn try_from(raw: RekorLogInfo) -> Result<Self, Self::Error> {
        Ok(LogInfo {
            root_hash: hex_to_hash_output(&raw.root_hash)?.into(),
            tree_size: raw.tree_size,
            signed_tree_head: raw.signed_tree_head,
            tree_id: raw.tree_id,
            inactive_shards: raw.inactive_shards,
        })
    }
}

impl LogInfo {
    pub fn new(root_hash: [u8; 32], tree_size: TreeSize, signed_tree_head: Checkpoint) -> LogInfo {
        LogInfo {
            root_hash,
            tree_size,
            signed_tree_head,
            tree_id: None,
            inactive_shards: None,
        }
    }
    /// Verify the consistency of the proof provided by the log.
    ///
    /// Example:
    /// ```rust
    /// use sigstore::crypto::{CosignVerificationKey, SigningScheme};
    /// use sigstore::rekor::apis::configuration::Configuration;
    /// use sigstore::rekor::apis::pubkey_api::get_public_key;
    /// use sigstore::rekor::apis::tlog_api::{get_log_info, get_log_proof};
    ///
    /// #[tokio::main]
    /// async fn main() {
    ///     let rekor_config = Configuration::default();
    ///
    ///     // Important: in practice obtain the rekor key via TUF repo or another secure channel!
    ///     let rekor_key = get_public_key(&rekor_config, None)
    ///         .await
    ///         .expect("failed to fetch pubkey from remote log");
    ///     let rekor_key =  CosignVerificationKey::from_pem(
    ///         rekor_key.as_bytes(),
    ///         &SigningScheme::ECDSA_P256_SHA256_ASN1,
    ///     ).expect("failed to parse rekor key");
    ///     // fetch log info twice and run consistency proof
    ///     let log_info1 = get_log_info(&rekor_config)
    ///         .await
    ///         .expect("failed to fetch data from remote");
    ///     let log_info2 = get_log_info(&rekor_config)
    ///         .await
    ///         .expect("failed to fetch data from remote");
    ///
    ///     // get a proof using log_info1 as the previous tree state
    ///     let proof = get_log_proof(
    ///         &rekor_config,
    ///         log_info2.tree_size as _,
    ///         Some(&log_info1.tree_size.to_string()),
    ///         None,
    ///     )
    ///     .await
    ///     .expect("failed to fetch data from remote");
    ///     
    ///     // verify proof for the new log info
    ///     log_info2
    ///         .verify_consistency(log_info1.tree_size, &log_info1.root_hash, &proof, &rekor_key)
    ///         .expect("failed to verify log consistency");
    /// }
    ///
    /// ```
    pub fn verify_consistency(
        &self,
        old_size: u64,
        old_root: &[u8; 32],
        consistency_proof: &ConsistencyProof,
        rekor_key: &CosignVerificationKey,
    ) -> Result<(), SigstoreError> {
        // verify checkpoint is signed by log
        self.signed_tree_head.verify_signature(rekor_key)?;

        self.signed_tree_head
            .is_valid_for_proof(&self.root_hash.into(), self.tree_size)?;
        consistency_proof.verify(
            old_size,
            old_root,
            self.tree_size as _,
            Some(&self.root_hash),
        )?;
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        crypto::{CosignVerificationKey, SigningScheme},
        rekor::models::{ConsistencyProof, RekorConsistencyProof},
    };

    use super::{LogInfo, RekorLogInfo};
    const LOG_INFO_OLD: &str = r#"
        {
            "inactiveShards": [
            {
                "rootHash": "ed4cb79f98642c7cd7626f8307d8fee48e04991dc4e827611884f131e53221ba",
                "signedTreeHead": "rekor.sigstage.dev - 8959784741570461564\n461\n7Uy3n5hkLHzXYm+DB9j+5I4EmR3E6CdhGITxMeUyIbo=\n\n— rekor.sigstage.dev 0y8wozBFAiBeSutKae/1zsGfMgCstDexSktqVfYgAKYaFNsBqYQ3cAIhAOewsY+B/oXGOILSBv3wduhlyn4wNmV3v1eRg3LOwHDi\n",
                "treeID": "8959784741570461564",
                "treeSize": 461
            },
            {
                "rootHash": "effa4fa4575f72829016a64e584441203de533212f9470d63a56d1992e73465d",
                "signedTreeHead": "rekor.sigstage.dev - 108574341321668964\n14358\n7/pPpFdfcoKQFqZOWERBID3lMyEvlHDWOlbRmS5zRl0=\n\n— rekor.sigstage.dev 0y8wozBFAiBJlYY/wJQw6hW3LzziTAp7SXjc7MfghJ31tiydO1MvrAIhAPCX7LQ5jUNOssRDFJPXX3DdQjdan+8UGrKzGgfayV0c\n",
                "treeID": "108574341321668964",
                "treeSize": 14358
            },
            {
                "rootHash": "ae6af751ddcfffc1b77386692d7eaa9b105c191cb613fad3e718183513b956f1",
                "signedTreeHead": "rekor.sigstage.dev - 8050909264565447525\n31667593\nrmr3Ud3P/8G3c4ZpLX6qmxBcGRy2E/rT5xgYNRO5VvE=\n\n— rekor.sigstage.dev 0y8wozBFAiEA6yozMl9lFn21m5mQHCJUyEiI3HOOuM5sIeVt/MU2MQMCIBDhFtWjwPKIjFSr/liQ8LY7K6LHQRvtzkoIrsWZ/c9a\n",
                "treeID": "8050909264565447525",
                "treeSize": 31667593
            }
            ],
            "rootHash": "e222aa53db49893334fb5a878ead1bf8b9f8f3c02ccfc0ae687f28256bd74907",
            "signedTreeHead": "rekor.sigstage.dev - 8202293616175992157\n1352760\n4iKqU9tJiTM0+1qHjq0b+Ln488Asz8CuaH8oJWvXSQc=\n\n— rekor.sigstage.dev 0y8wozBFAiEAnIjdHAH9uhqBrRNBA4bMaKR30H6qdzW4TAsdB0/KP0ICIDjK9VeE+9dWXSAm/B0aPkhO7pJMLmKPjo9btFD9ZvEs\n",
            "treeID": "8202293616175992157",
            "treeSize": 1352760
        }"#;

    const LOG_INFO_NEW: &str = r#"
        {
            "inactiveShards": [
            {
                "rootHash": "ed4cb79f98642c7cd7626f8307d8fee48e04991dc4e827611884f131e53221ba",
                "signedTreeHead": "rekor.sigstage.dev - 8959784741570461564\n461\n7Uy3n5hkLHzXYm+DB9j+5I4EmR3E6CdhGITxMeUyIbo=\n\n— rekor.sigstage.dev 0y8wozBFAiEAvtvC/roj8MxqTqvyHaq5pVHQ4eWJwNb/BpMNGLrjPdYCIB5rWm8b1FCsnVUty27Gyvod3PB9MgG6ar24XDYrNSau\n",
                "treeID": "8959784741570461564",
                "treeSize": 461
            },
            {
                "rootHash": "effa4fa4575f72829016a64e584441203de533212f9470d63a56d1992e73465d",
                "signedTreeHead": "rekor.sigstage.dev - 108574341321668964\n14358\n7/pPpFdfcoKQFqZOWERBID3lMyEvlHDWOlbRmS5zRl0=\n\n— rekor.sigstage.dev 0y8wozBFAiEA5zsLKvJeAuSc61IxVqNKnyVA0FIOZFck/cQl1BoYj0kCICMOJUulfDbukn5ApybPKUJ20nsFQ0P/54ku3/bl0Thq\n",
                "treeID": "108574341321668964",
                "treeSize": 14358
            },
            {
                "rootHash": "ae6af751ddcfffc1b77386692d7eaa9b105c191cb613fad3e718183513b956f1",
                "signedTreeHead": "rekor.sigstage.dev - 8050909264565447525\n31667593\nrmr3Ud3P/8G3c4ZpLX6qmxBcGRy2E/rT5xgYNRO5VvE=\n\n— rekor.sigstage.dev 0y8wozBEAiBok3nxMEarLtLkNJFCq+4A3r1givc2YZqO48quIGEOrgIgUGJwm2+yr59SH/Vmf7+XxPY/mMIuyXlP6OXDdnHglF0=\n",
                "treeID": "8050909264565447525",
                "treeSize": 31667593
            }
            ],
            "rootHash": "c7d98fcf73e06fb3b7a6c02648dee52567a4b7b6db1dae31ec723283b379c782",
            "signedTreeHead": "rekor.sigstage.dev - 8202293616175992157\n1352764\nx9mPz3Pgb7O3psAmSN7lJWekt7bbHa4x7HIyg7N5x4I=\n\n— rekor.sigstage.dev 0y8wozBGAiEAiU8vSPj7yujJ2R6ES8t2AXJG+uezCj5Th7Dp6U5kBU0CIQCDObTWELwMeAa0u1VndfB+WvXEXKtYTNm5QXzK7d7xhA==\n",
            "treeID": "8202293616175992157",
            "treeSize": 1352764
        }"#;
    /// Consistency proof requested via: https://rekor.sigstage.dev/api/v1/log/proof?lastSize=1352764&firstSize=1352760&treeId=8202293616175992157
    const LOG_PROOF: &str = r#"
        {
            "hashes": [
                "2713ba8ade1872a38adf7d108e5cedf5056fbde30c6d19fcc10f965e9fc1373e",
                "2197a8f07628339739e65c2cc1d16fd36ccca1ef980d5966de82259a56821145",
                "bc6015344bdfce14a2d24d4230ae734002220557f7a930c8fbc17e1e3e86b692",
                "156bdcfc96e73a81f2255c4e05936ef0b50a0862213f4b863af228f4fa4f20ca",
                "a6c2a8510ab7f123bc4cc7927e1f3156bf324bfceafee6ecae8597739cb4b436",
                "299a7084ca00c8be9dfbf176291a266599308a014edc9c5ddacc07821d003837",
                "153a44af92202f031e457d09930fd53c85e519bf3a4b79a11b1d946e65a28da8",
                "3abe35db1c15b4710d9cf755a11f32d95f4e58907ac54fef389bfcf18c231f38",
                "e0300bb7400e692bccbf20b17fe7ec177aba23e7bfd36dcb7484935ccd214336"
            ],
            "rootHash": "437afb5d68e7f875cd91311f6549f4f12324418b39bdbf96cffe3884cb9e8f26"
        }"#;

    /// Pubkey for `rekor.sigstage.dev`.
    const REKOR_STAGING_KEY_PEM: &str = r#"
    -----BEGIN PUBLIC KEY-----
    MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEDODRU688UYGuy54mNUlaEBiQdTE9
    nYLr0lg6RXowI/QV/RE1azBn4Eg5/2uTOMbhB1/gfcHzijzFi9Tk+g1Prg==
    -----END PUBLIC KEY-----
"#;

    #[test]
    fn test_consistency_valid() {
        let rekor_key = CosignVerificationKey::from_pem(
            REKOR_STAGING_KEY_PEM.as_bytes(),
            &SigningScheme::ECDSA_P256_SHA256_ASN1,
        )
        .expect("failed to parse Rekor key");
        let log_info_old_raw: RekorLogInfo =
            serde_json::from_str(LOG_INFO_OLD).expect("failed to deserialize log info test data");
        let log_info_old: LogInfo =
            LogInfo::try_from(log_info_old_raw).expect("failed to convert log info data");
        let log_info_new_raw: RekorLogInfo =
            serde_json::from_str(LOG_INFO_NEW).expect("failed to deserialize log info test data");
        let log_info_new: LogInfo =
            LogInfo::try_from(log_info_new_raw).expect("failed to convert log info data");
        let consistency_proof_raw: RekorConsistencyProof =
            serde_json::from_str(LOG_PROOF).expect("failed to deserialize log proof data");
        let consistency_proof = ConsistencyProof::try_from(consistency_proof_raw)
            .expect("failed to convert log proof data");

        log_info_new
            .verify_consistency(
                log_info_old.tree_size,
                &log_info_old.root_hash,
                &consistency_proof,
                &rekor_key,
            )
            .expect("failed to accept valid inclusion proof");
    }

    #[test]
    fn test_consistency_invalid() {
        let rekor_key = CosignVerificationKey::from_pem(
            REKOR_STAGING_KEY_PEM.as_bytes(),
            &SigningScheme::ECDSA_P256_SHA256_ASN1,
        )
        .expect("failed to parse Rekor key");
        let log_info_old_raw: RekorLogInfo =
            serde_json::from_str(LOG_INFO_OLD).expect("failed to deserialize log info test data");
        let log_info_old: LogInfo =
            LogInfo::try_from(log_info_old_raw).expect("failed to convert log info data");
        let log_info_new_raw: RekorLogInfo =
            serde_json::from_str(LOG_INFO_NEW).expect("failed to deserialize log info test data");
        let log_info_new: LogInfo =
            LogInfo::try_from(log_info_new_raw).expect("failed to convert log info data");

        let consistency_proof_raw: RekorConsistencyProof =
            serde_json::from_str(LOG_PROOF).expect("failed to deserialize log proof data");
        let consistency_proof = ConsistencyProof::try_from(consistency_proof_raw)
            .expect("failed to convert log proof data");

        let mut test_cases = vec![];

        let mut consistency_proof_empty = consistency_proof.clone();
        consistency_proof_empty.hashes = vec![];
        test_cases.push((consistency_proof_empty, "empty proof"));

        let mut consistency_proof_additional_hash_raw: RekorConsistencyProof =
            serde_json::from_str(LOG_PROOF).expect("failed to deserialize log proof data");
        consistency_proof_additional_hash_raw
            .hashes
            .push("e0300bb7400e692bccbf20b17fe7ec177aba23e7bfd36dcb7484935ccd214336".to_string());
        let consistency_proof_additional_hash =
            ConsistencyProof::try_from(consistency_proof_additional_hash_raw)
                .expect("failed to convert log proof data");
        test_cases.push((consistency_proof_additional_hash, "too many hashes"));

        let mut consistency_proof_removed_hash = consistency_proof.clone();
        let _ = consistency_proof_removed_hash.hashes.pop().unwrap();
        test_cases.push((consistency_proof_removed_hash, "too few hashes"));

        // invert all the hashes in the proof
        let mut consistency_proof_invalid_hash = consistency_proof.clone();
        consistency_proof_invalid_hash.hashes = consistency_proof_invalid_hash
            .hashes
            .into_iter()
            .map(|mut h| {
                h.reverse();
                h
            })
            .collect();

        test_cases.push((consistency_proof_invalid_hash, "invalid hashes"));

        for (proof, desc) in test_cases {
            let res = log_info_new.verify_consistency(
                log_info_old.tree_size,
                &log_info_old.root_hash,
                &proof,
                &rekor_key,
            );
            assert!(res.is_err(), "accepted invalid proof:  {desc}");
        }
    }
}
